{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350479d3",
   "metadata": {},
   "source": [
    "# Network analysis for comparing Perry Rhodan character network with prototypical network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78657f18",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd963f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snap\n",
    "import statistics\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a9b31",
   "metadata": {},
   "source": [
    "## Functions generating network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d2cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_set_up(output_file):\n",
    "    '''function loads perry rhodan edge and node lists from files and creates network in SNAP'''\n",
    "    \n",
    "    output_file.write('P E R R Y  R H O D A N\\n')\n",
    "    \n",
    "    # Edge list must be a tab separated file (remove whitespace before analysis):\n",
    "    perry_graph, a = snap.LoadEdgeListStr(snap.TUNGraph, \"../network_data/data_for_network_analysis/edge_list.csv\", 0, 1, True)\n",
    "    \n",
    "    # Adding nodes with degree 0; node list must be a tab separated file (remove whitespace before analysis):\n",
    "    with open(\"../network_data/data_for_network_analysis/node_list_deg_0.csv\") as file:\n",
    "        text = file.read()\n",
    "    node_list = list(perry_graph.Nodes())\n",
    "    i = len(node_list)\n",
    "    for node_name in text.split(\"\\n\"):\n",
    "        perry_graph.AddNode(i)\n",
    "        i += 1\n",
    "    \n",
    "    # clean up accidental mistakes in data:\n",
    "    perry_graph.MakeUnDir()\n",
    "    perry_graph.DelSelfEdges()\n",
    "    \n",
    "    # print basic info in output file:\n",
    "    nodes = list(perry_graph.Nodes())\n",
    "    edges = list(perry_graph.Edges())\n",
    "    output_file.write(f'{len(nodes)} Knoten und {len(edges)} Kanten im Graphen.\\n')\n",
    "    \n",
    "    return perry_graph, len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a95a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_networks (type, output_file, network_size, sample_size):\n",
    "    '''generates 10 random networks for a given type (small-world, core-periphery, scale-free and random) and writes network analysis results in file'''\n",
    "    \n",
    "    graphs = []\n",
    "    Rnd = snap.TRnd(0,100)\n",
    "\n",
    "    if type == \"small-world\":\n",
    "        output_file.write(\"\\nS M A L L - W O R L D\\n\")\n",
    "        for x in range(sample_size):\n",
    "            graphs.append(snap.GenSmallWorld(network_size, 8, 0.1, Rnd))\n",
    "\n",
    "    elif type == \"core-periphery\":\n",
    "        output_file.write(\"\\nC O R E - P E R I P H E R Y\\n\")\n",
    "        for x in range(sample_size):\n",
    "            # core-periphery network has to be manually generated: 5 fully connected nodes in the core, each one with a chance to be connected with up to 3335 other (periphery) nodes.\n",
    "            graph = snap.TUNGraph.New()\n",
    "\n",
    "            # adds n (unconnected) nodes into the graph\n",
    "            for i in range(network_size):\n",
    "                graph.AddNode(i)\n",
    "\n",
    "            # fully connects core nodes #0 - #4\n",
    "            graph.AddEdge(0,1)\n",
    "            graph.AddEdge(0,2)\n",
    "            graph.AddEdge(0,3)\n",
    "            graph.AddEdge(0,4)\n",
    "            graph.AddEdge(1,2)\n",
    "            graph.AddEdge(0,3)\n",
    "            graph.AddEdge(0,4)\n",
    "            graph.AddEdge(2,3)\n",
    "            graph.AddEdge(2,4)\n",
    "            graph.AddEdge(3,4)\n",
    "\n",
    "            # generate indices for five equally sized parts\n",
    "            equal_part = int(network_size/5)\n",
    "            equal_first = 1*equal_part\n",
    "            equal_second = 2*equal_part\n",
    "            equal_third = 3*equal_part\n",
    "            equal_fourth = 4*equal_part\n",
    "\n",
    "            # iterates through all other nodes giving them a chance (0.9) to be connected to a core node and otherwise connects them to the previously added node \n",
    "            for i in range(5, equal_part):\n",
    "                if random.random() > 0.1:\n",
    "                    graph.AddEdge(0,i)\n",
    "                    graph.AddEdge(1,i+equal_first)\n",
    "                    graph.AddEdge(2,i+equal_second)\n",
    "                    graph.AddEdge(3,i+equal_third)\n",
    "                    graph.AddEdge(4,i+equal_fourth)\n",
    "                else:\n",
    "                    graph.AddEdge(i-1,i)\n",
    "                    graph.AddEdge(i+equal_first-1,i+equal_first)\n",
    "                    graph.AddEdge(i+equal_second-1,i+equal_second)\n",
    "                    graph.AddEdge(i+equal_third-1,i+equal_third)\n",
    "                    graph.AddEdge(i+equal_fourth-1,i+equal_fourth)\n",
    "\n",
    "            # graph is undirected\n",
    "            graph.MakeUnDir()\n",
    "\n",
    "            graphs.append(graph)\n",
    "\n",
    "    elif type == \"scale-free\":\n",
    "        output_file.write(\"\\nS C A L E - F R E E\\n\")\n",
    "        for x in range(sample_size):\n",
    "            graphs.append(snap.GenPrefAttach(network_size, 8, Rnd))\n",
    "\n",
    "    elif type == \"random\":\n",
    "        output_file.write(\"\\nR A N D O M\\n\")\n",
    "        for x in range(sample_size):\n",
    "            graphs.append(snap.GenRndGnm(snap.TUNGraph, network_size, 65000, False, Rnd))\n",
    "    \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd447cc2",
   "metadata": {},
   "source": [
    "## Functions computing network measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db47c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_distribution (graph):\n",
    "    '''returns degree distribution for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing degree distribution\")\n",
    "    \n",
    "    mean = []\n",
    "    DegToCntV = graph.GetDegCnt()\n",
    "    \n",
    "    for item in DegToCntV:\n",
    "        degree = item.GetVal1()\n",
    "        for i in range(item.GetVal2()):\n",
    "            mean.append(degree)\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7f4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diameter (graph):\n",
    "    '''returns diameter for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing diameter\")\n",
    "    \n",
    "    diam = graph.GetBfsEffDiamAll(100, False)\n",
    "    \n",
    "    return diam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c152209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weakly_connected_components(graph):\n",
    "    '''returns weakly connected components score for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing weakly connected components\")\n",
    "    \n",
    "    ComponentDist = graph.GetWccSzCnt()\n",
    "    wcc = 0\n",
    "    \n",
    "    for comp in ComponentDist:\n",
    "        # print(f\"Size: {comp.GetVal1()} - Number of Components: {comp.GetVal2()}\")\n",
    "        wcc += comp.GetVal2()\n",
    "    \n",
    "    return wcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd79e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clust_coef (graph):\n",
    "    '''returns cluster coefficient for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing cluster coefficient\")\n",
    "    \n",
    "    cluster = graph.GetClustCf()\n",
    "    \n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad59ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_core (graph):\n",
    "    '''returns k-core score for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing k-core\")\n",
    "    \n",
    "    k_core = graph.GetKCoreNodes()\n",
    "    \n",
    "    return k_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb03c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_centralization (graph):\n",
    "    '''returns degree centralization score for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing degree centralization\")\n",
    "    \n",
    "    n = len(list(graph.Nodes()))\n",
    "    degrees = graph.GetDegSeqV()\n",
    "    max_deg = max(degrees)\n",
    "    centralization = (n * max_deg - sum(degrees)) / ((n - 2) * (n - 1))\n",
    "    \n",
    "    return centralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df060baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centralization (graph):\n",
    "    '''returns betweenness centralization score for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing betweenness centralization\")\n",
    "    \n",
    "    n = len(list(graph.Nodes()))\n",
    "    betws = []\n",
    "    centralization = 0\n",
    "\n",
    "    nodes, edges = graph.GetBetweennessCentr()\n",
    "\n",
    "    for i in range(n):\n",
    "        betws.append(nodes[i])\n",
    "    max_betw = max(betws)\n",
    "    max_betw_norm = (2 * max_betw) / ((n - 1) * (n - 2))\n",
    "    min_betw = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        betw = (2 * nodes[i]) / ((n - 1) * (n - 2))\n",
    "        centralization += (max_betw_norm - betw)\n",
    "    result = centralization / (n - 1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93a3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness_centralization (graph):\n",
    "    '''returns closeness centralization score for given graph'''\n",
    "    \n",
    "    print(\"\\tanalysing closeness centralization\")\n",
    "    \n",
    "    nodes = []\n",
    "    n = len(list(graph.Nodes()))\n",
    "    for i in range(n):\n",
    "        nodes.append(graph.GetClosenessCentr(i,True,False))\n",
    "    max_clos = max(nodes)\n",
    "    centralization = 0\n",
    "    closeness = (n * max_clos) - sum(nodes)\n",
    "    result = (closeness * (2 * n- 3)) / ((n - 1)*(n - 2))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b87d2",
   "metadata": {},
   "source": [
    "## Functions coordinating analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84661924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_single_graph (graph, output_file):\n",
    "    '''function writes network analysis results for a single given graph to file'''\n",
    "    \n",
    "    # Get network measures for given graph:\n",
    "    mean = degree_distribution(graph)\n",
    "    diam = diameter(graph)\n",
    "    cluster = clust_coef(graph)\n",
    "    number, kcores = k_core(graph)\n",
    "    cent = degree_centralization(graph)\n",
    "    betw = betweenness_centralization(graph)\n",
    "    clos = closeness_centralization(graph)\n",
    "    wcc = weakly_connected_components(graph)\n",
    "    \n",
    "    # Write results to output file:\n",
    "    output_file.write(f'Mittelwert der Gradverteilung bei: {statistics.mean(mean)}.\\n')\n",
    "    output_file.write(f'Standardabweichung bei: {statistics.stdev(mean)}.\\n')\n",
    "    output_file.write(f'Median bei: {statistics.median(mean)}.\\n')\n",
    "    output_file.write(\n",
    "        f'Durchmesser: {diam[2]}, effektiver Durchmesser: {diam[1]} und die durchschnittliche kürzeste Pfadlänge: {diam[3]}.\\n')\n",
    "    output_file.write(f'Cluster-Koeffizient: {cluster}.\\n')\n",
    "    output_file.write(f'Anzahl der schwach verbundenen Komponenten: {wcc}.\\n')\n",
    "    output_file.write(f'Der höchste K-Core der Ordnung {kcores[number - 1].GetVal1()} mit {kcores[number - 1].GetVal2()} Knoten.\\n')\n",
    "    output_file.write(f'Die Degree-Centralization liegt bei: {cent}.\\n')\n",
    "    output_file.write(f'Die Betweenness-Centralization liegt bei: {betw}.\\n')\n",
    "    output_file.write(f'Die Closeness-Centralization liegt bei: {clos}.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01673183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_multiple_graphs (graph_list, output_file):\n",
    "    '''calculates network analysis scores for a list of graphs and writes the respective arithmetic mean to file'''\n",
    "    \n",
    "    # Get lists of network measures for given graphs:\n",
    "    degs, diams, clusts, paths, deg_cents, betw_cents = [], [], [], [], [], []\n",
    "    for graph in graph_list:\n",
    "        degs.append(statistics.mean(degree_distribution(graph)))\n",
    "        diam = diameter(graph)\n",
    "        paths.append(diam[3])\n",
    "        diams.append(diam[2])\n",
    "        clusts.append(clust_coef(graph))\n",
    "        deg_cents.append(degree_centralization(graph))\n",
    "    betw_cents.append(betweenness_centralization(graph_list[0]))\n",
    "    \n",
    "    # Write results (arithmetic mean) to output file:\n",
    "    output_file.write(f'Durchschnittlicher Grad: {statistics.mean(degs)}.\\n')\n",
    "    output_file.write(f'Durschnittlicher kürzester Pfad: {statistics.mean(paths)}.\\n')\n",
    "    output_file.write(f'Durchschnittlicher Durchmesser: {statistics.mean(diams)}.\\n')\n",
    "    output_file.write(f'Durchschnittlicher Clustering-Koeffizient: {statistics.mean(clusts)}.\\n')\n",
    "    output_file.write(f'Durchschnittliche Degree Centralization: {statistics.mean(deg_cents)}.\\n')\n",
    "    output_file.write(f'Random Betweenness Centralization: {statistics.mean(betw_cents)}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd033d",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed7fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysing Perry-Rhodan network...\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing k-core\n",
      "\tanalysing degree centralization\n",
      "\tanalysing betweenness centralization\n",
      "\tanalysing closeness centralization\n",
      "\tanalysing weakly connected components\n",
      "...done.\n",
      "analysing small-world networks...\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing betweenness centralization\n",
      "...done.\n",
      "analysing core-periphery networks...\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing betweenness centralization\n",
      "...done.\n",
      "analysing scale-free networks...\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing betweenness centralization\n",
      "...done.\n",
      "analysing random networks...\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing degree distribution\n",
      "\tanalysing diameter\n",
      "\tanalysing cluster coefficient\n",
      "\tanalysing degree centralization\n",
      "\tanalysing betweenness centralization\n",
      "...done.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with open(\"../results_network-analysis/results.txt\", \"w\") as report:\n",
    "        try:\n",
    "            print(\"analysing Perry-Rhodan network...\")\n",
    "            perry_graph, network_size = graph_set_up(report)\n",
    "            # get network_size from Perry-Rhodan network\n",
    "            describe_single_graph(perry_graph, report)\n",
    "            report.write(\"\\n##########\\n\")\n",
    "            print(\"...done.\")\n",
    "\n",
    "            print(\"analysing small-world networks...\")\n",
    "            rand_graphs = generate_networks(\"small-world\", report, network_size, 5)\n",
    "            describe_multiple_graphs(rand_graphs, report)\n",
    "            report.write(\"\\n##########\\n\")\n",
    "            print(\"...done.\")\n",
    "\n",
    "            print(\"analysing core-periphery networks...\")\n",
    "            cp_graphs = generate_networks(\"core-periphery\", report, network_size, 5)\n",
    "            describe_multiple_graphs(cp_graphs, report)\n",
    "            report.write(\"\\n##########\\n\")\n",
    "            print(\"...done.\")\n",
    "\n",
    "            print(\"analysing scale-free networks...\")\n",
    "            scalefree_graphs = generate_networks(\"scale-free\", report, network_size, 5)\n",
    "            describe_multiple_graphs(scalefree_graphs, report)\n",
    "            report.write(\"\\n##########\\n\")\n",
    "            print(\"...done.\")\n",
    "\n",
    "            print(\"analysing random networks...\")\n",
    "            rand_graphs = generate_networks(\"random\", report, network_size, 5)\n",
    "            describe_multiple_graphs(rand_graphs, report)\n",
    "            report.write(\"\\n##########\\n\")\n",
    "            print(\"...done.\")\n",
    "        finally:\n",
    "            report.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
